{
"cells": [
 {
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "<h1 align=\"center\"><font color=\"0066FF\" size=110>Linear Equations & Iterative Methods</font></h1>\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "import matplotlib.pyplot as plt\n",
  "try:\n",
  "    %matplotlib inline\n",
  "except: # not in notebook\n",
  "    pass\n",
  "LECTURE = False\n",
  "if LECTURE:\n",
  "    matplotlib.rcParams['font.size', 20]\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "# Learning Outcomes\n",
  "\n",
  "After studying this notebook you should be able to\n",
  "-   Give the motivation for using iterative methods to solve linear equations, as opposed to direct solver like Gaussian Elimination.\n",
  "-   Describe the algorithm for the Jacobi Iteration method\n",
  "-   Describe the algorithm for the Gauss-Seider and relaxed Gauss-Seider methods.\n",
  "-   Test whether a given linear equation can be solved by using the Jacobi or Gauss-Seider methods.\n",
  "\n",
  "# Introduction\n",
  "\n",
  "Direct solvers such as Gaussian Elimination and LU decomposition allow for efficient solving. In this section we introduce iterative solutions methods. The choice of a direct method or an indirect method is a combination of the efficiency of the method (and in general iterative methods are more efficient), the particular structure of the matrix system, a trade-off between compute time and memory, and the computer architecture being used.\n",
  "\n",
  "Iterative methods work by refining a guess to the solution and converging as quickly as possible from that guess to the actual solution. You may have met iterative methods previously in, for example, the general purpose solution of non-linear equations– such as bisection or Newton-Raphson techniques (along with their more advanced cousins).\n",
  "Iterative methods for linear systems have become a widespread and powerful tool for solving the most complex scientific and engineering problems and can be extremely effective, especially when starting from a good guess at the final solution – and often effort is expended in making that initial guess as good as possible and which will start you off close to the final solution and yield a more rapid convergence to the answer. Their only drawback is that they may not necessarily converge to a solution for a particular matrix system.\n",
  "\n",
  "In this section we will assume familiarity with linear equations of the form:\n",
  "\n",
  "\\begin{equation}\n",
  "Ax = \\begin{pmatrix}\n",
  "          a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
  "          a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
  "          \\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
  "          a_{n1} & a_{n2} & \\cdot & a_{nn}\n",
  "    \\end{pmatrix}\n",
  "    \\begin{pmatrix}\n",
  "    x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\n",
  "    \\end{pmatrix}\n",
  "    =\n",
  "    \\begin{pmatrix}\n",
  "    b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n\n",
  "    \\end{pmatrix}\n",
  "    = b\n",
  "\\end{equation}\n",
  "\n",
  "and their solution by Gaussian Elimination, LU Decomposition, along with issues which can arise such as a singular matrix, ill-conditioning, and poor scaling. We will also assume knowledge of norms matrices and vectors.\n",
  "\n",
  "# Jacobi Iteration\n",
  "\n",
  "Consider the set of equations (derived from Ref 1 Ex 3.26)\n",
  "\n",
  "\\begin{equation}\n",
  "     \\begin{pmatrix}\n",
  "     4 & -1 & 1 \\\\\n",
  "     4 & -8 & 1 \\\\\n",
  "     -2 & 1 & 5\n",
  "     \\end{pmatrix}\n",
  "     \\begin{pmatrix}\n",
  "     x_1 \\\\ x_2 \\\\ x_3\n",
  "     \\end{pmatrix}\n",
  "     =\n",
  "     \\begin{pmatrix}\n",
  "     7 \\\\ -21 \\\\ 15\n",
  "     \\end{pmatrix}\n",
  "\\end{equation}\n",
  "\n",
  "These could be written:\n",
  "\n",
  "\\begin{align}\n",
  "x_1 &= \\frac{7 + x_2 - x_3}{4}   \\\\\n",
  "x_2 &= \\frac{21 + 4x_1 + x_3}{8} \\\\\n",
  "x_3 &= \\frac{15 + 2x_1 - x_2}{5}\n",
  "\\end{align}\n",
  "\n",
  "And we could derive an iteration scheme which cycles through each of the values of $x_1$, $x_2$, and $x_3$ in turn to refine an initial guess. If $k$ is the k-th iteration, then $x_1^{(k+1)}$ is the next guess for $x_1$:\n",
  "\n",
  "\\begin{align}\n",
  "x_1^{(k + 1)} &= \\frac{7 + x_2^{(k)} - x_3^{(k)}}{4}   \\\\\n",
  "x_2^{(k + 1)} &= \\frac{21 + 4x_1^{(k)} + x_3^{(k)}}{8} \\\\\n",
  "x_3^{(k + 1)} &= \\frac{15 + 2x_1^{(k)} - x_2^{(k)}}{5}\n",
  "\\end{align}\n",
  "\n",
  "Starting with an initial guess of (1,2,2) we obtain:\n",
  "\n",
  "\\begin{align}\n",
  "x_1^{(1)} &= \\frac{7 + 2 - 2}{4} = 1.75   \\\\\n",
  "x_2^{(1)} &= \\frac{21 + 4 + 2}{8} = 3.375 \\\\\n",
  "x_3^{(1)} &= \\frac{15 + 2 - 2}{5} = 3.00\n",
  "\\end{align}\n",
  "\n",
  "In general we can write the Jacobi scheme as:\n",
  "\n",
  "\\begin{equation}\n",
  "x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{\\substack{j=1 \\\\ j \\neq i}}^n a_{ij} x_j^{(k)}\\right), \\qquad i=1, 2, \\cdots, n\n",
  "\\end{equation}\n",
  "\n",
  "The following table shows subsequent iterations\n",
  "\n",
  "<table border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\" frame=\"hsides\">\n",
  "\n",
  "\n",
  "<colgroup>\n",
  "<col  class=\"right\" />\n",
  "\n",
  "<col  class=\"right\" />\n",
  "\n",
  "<col  class=\"right\" />\n",
  "\n",
  "<col  class=\"right\" />\n",
  "</colgroup>\n",
  "<thead>\n",
  "<tr>\n",
  "<th scope=\"col\" class=\"right\">$k$</th>\n",
  "<th scope=\"col\" class=\"right\">$x_1^{(k)}$</th>\n",
  "<th scope=\"col\" class=\"right\">$x_2^{(k)}$</th>\n",
  "<th scope=\"col\" class=\"right\">$x_3^{(k)}$</th>\n",
  "</tr>\n",
  "</thead>\n",
  "\n",
  "<tbody>\n",
  "<tr>\n",
  "<td class=\"right\">0</td>\n",
  "<td class=\"right\">1.0</td>\n",
  "<td class=\"right\">2.0</td>\n",
  "<td class=\"right\">2.0</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">1</td>\n",
  "<td class=\"right\">1.75</td>\n",
  "<td class=\"right\">3.375</td>\n",
  "<td class=\"right\">3.0</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">2</td>\n",
  "<td class=\"right\">1.84375</td>\n",
  "<td class=\"right\">3.875</td>\n",
  "<td class=\"right\">3.025</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">3</td>\n",
  "<td class=\"right\">1.9625</td>\n",
  "<td class=\"right\">3.925</td>\n",
  "<td class=\"right\">2.9625</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">19</td>\n",
  "<td class=\"right\">2.0000</td>\n",
  "<td class=\"right\">4.0000</td>\n",
  "<td class=\"right\">3.0000</td>\n",
  "</tr>\n",
  "</tbody>\n",
  "</table>\n",
  "\n",
  "Python example code from Ref 2:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "from pprint import pprint\n",
  "from numpy import array, zeros, diag, diagflat, dot\n",
  "\n",
  "def jacobi(A,b,N=25,x=None, info=True):\n",
  "    \"\"\"Solves the equation Ax=b via the Jacobi iterative method.\"\"\"\n",
  "    # Create an initial guess if needed\n",
  "    if x is None:\n",
  "        x = zeros(len(A[0]))\n",
  "\n",
  "    # Create a vector of the diagonal elements of A\n",
  "    # and subtract them from A\n",
  "    D = diag(A)\n",
  "    R = A - diagflat(D)\n",
  "\n",
  "    # Iterate for N times\n",
  "    for i in range(N):\n",
  "        x = (b - dot(R,x))/D\n",
  "        if info:\n",
  "            pprint(x)\n",
  "    return x\n",
  "\n",
  "# Set up problem here\n",
  "A = array([[4.0, -1.0, 1.0],[4.0, -8.0, 1.0] , [ -2.0, 1.0, 5.0]])\n",
  "b = array([7.0 , -21.0, 15.0])\n",
  "guess = array([1.0,2.0,2.0])\n",
  "\n",
  "# Solve\n",
  "sol = jacobi(A,b,N=25,x=guess)\n",
  "\n",
  "print \"A:\"\n",
  "pprint(A)\n",
  "\n",
  "print \"b:\"\n",
  "pprint(b)\n",
  "\n",
  "print \"x:\"\n",
  "pprint(sol)\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "\n",
  "\n",
  "## Convergence\n",
  "\n",
  "It is a sufficient condition for the matrix to be *strictly diagonally dominant* for the Jacobi method to converge from any given starting vector.\n",
  "A matrix is said to be strictly diagonally dominant if\n",
  "\n",
  "\\begin{equation}\n",
  "|a_{ii}| > \\sum_{\\substack{j=1 \\\\ j \\neq i}}^n |a_{ij}|, \\qquad i=1, 2, \\cdots, n.\n",
  "\\end{equation}\n",
  "\n",
  "In the example above, we have\n",
  "\n",
  "\\begin{align}\n",
  "&\\text{Row 1}: & |4| &> |-1| + |1| \\\\\n",
  "&\\text{Row 2}: & |-8| &> |4| + |1| \\\\\n",
  "&\\text{Row 3}: & |5| &> |-2| + |1|\n",
  "\\end{align}\n",
  "\n",
  "and the method will always converge for any given starting vector.\n",
  "\n",
  "## Exercise 1\n",
  "\n",
  "-   Solve the linear equation $A_2 x = b_2$ using Jacobi Iteration, where\n",
  "\n",
  "\\begin{align}\n",
  "     A_2 &=\\begin{pmatrix}\n",
  "       -2 & 1 & 5 \\\\\n",
  "        4 & -8 & 1 \\\\\n",
  "        4 & -1 & 1\n",
  "     \\end{pmatrix},\n",
  "     &\n",
  "     b_2 &= \\begin{pmatrix}\n",
  "     15 \\\\ -21 \\\\ 7\n",
  "     \\end{pmatrix}\n",
  "\\end{align}\n",
  "\n",
  "and explain what happens. Skeleton code:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "A2 = array([[ -2.0, 1.0, 5.0], [4.0, -8.0, 1.0] , [4.0, -1.0, 1.0] ])\n",
  "b2 = array([15.0 , -21.0, 7.0])\n",
  "guess = array([1.0,2.0,2.0])\n",
  "\n",
  "\n",
  "xold = 0\n",
  "errlst = []\n",
  "iterlst = [2, 4, 8, 16, 32, 64]\n",
  "for N in iterlst:\n",
  "    x = jacobi(A2, b2, N, info=False)\n",
  "    dx = dot(x - xold, x - xold)\n",
  "    print dx\n",
  "    errlst.append(dx)\n",
  "    xold = x.copy()\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "Plot the evolution of the error:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "\n",
  "# Plot\n",
  "plt.figure(1)\n",
  "plt.clf()\n",
  "plt.semilogy(iterlst, errlst, 'o-')\n",
  "plt.xlabel('number of iterations')\n",
  "plt.ylabel('error')\n",
  "plt.savefig(\"fig01-01.pdf\")\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "-   Implement a function that tests whether a matrix is diagonnally dominant. Skeleton code:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "import numpy as np\n",
  "\n",
  "def isdiagdom(A):\n",
  "    \"\"\"Takes a square matrix-like object A as input and returns True\n",
  "    if matrix A is strictly diagonnally dominant, False otherwise.\n",
  "    \"\"\"\n",
  "    d = np.diag(A)  # vector of diagonal coefficients of A\n",
  "    D = np.diagflat(d)  # a diagonal matrix\n",
  "    # sum(a_ij over j)\n",
  "    col_sums = np.sum(np.abs(A - D), axis=1)\n",
  "    return np.all(abs(d) > col_sums)\n",
  "\n",
  "# Tests\n",
  "print 'matrix A diagonally dominant = ', isdiagdom(A)\n",
  "print 'matrix A2 diagonally dominant = ', isdiagdom(A2)\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "# Gauss-Seider (with relaxation)\n",
  "\n",
  "In the Jacobi scheme at each stage when we update the $x_i^{(k+1)}$ at each iteration we always use the value for $x_i^{(k)}$ from the previous iteration– yet looking at the equations (2.5), why not use the value of $x_1^{(k+1)}$, when we compute $x_2^{(k+1)}$ as this is available to us. Thus the equations would become:\n",
  "\n",
  "\\begin{align}\n",
  "x_1^{(k + 1)} &= \\frac{7 + x_2^{(k)} - x_3^{(k)}}{4}   \\\\\n",
  "x_2^{(k + 1)} &= \\frac{21 + 4x_1^{(k+1)} + x_3^{(k)}}{8} \\\\\n",
  "x_3^{(k + 1)} &= \\frac{15 + 2x_1^{(k+1)} - x_2^{(k+1)}}{5}\n",
  "\\end{align}\n",
  "\n",
  "Making this change and repeating the above makes the iteration to the solution (2,4,3) take only 10 steps as per the table below\n",
  "\n",
  "<table border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\" frame=\"hsides\">\n",
  "\n",
  "\n",
  "<colgroup>\n",
  "<col  class=\"right\" />\n",
  "\n",
  "<col  class=\"right\" />\n",
  "\n",
  "<col  class=\"right\" />\n",
  "\n",
  "<col  class=\"right\" />\n",
  "</colgroup>\n",
  "<tbody>\n",
  "<tr>\n",
  "<td class=\"right\">$k$</td>\n",
  "<td class=\"right\">$x_1^{(k)}$</td>\n",
  "<td class=\"right\">$x_2^{(k)}$</td>\n",
  "<td class=\"right\">$x_3^{(k)}$</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">0</td>\n",
  "<td class=\"right\">1.0</td>\n",
  "<td class=\"right\">2.0</td>\n",
  "<td class=\"right\">3.0</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">1</td>\n",
  "<td class=\"right\">1.75</td>\n",
  "<td class=\"right\">3.75</td>\n",
  "<td class=\"right\">2.95</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">2</td>\n",
  "<td class=\"right\">1.95</td>\n",
  "<td class=\"right\">3.96875</td>\n",
  "<td class=\"right\">2.98625</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">3</td>\n",
  "<td class=\"right\">1.995625</td>\n",
  "<td class=\"right\">3.99609375</td>\n",
  "<td class=\"right\">2.99903125</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "<td class=\"right\">&#x2026;</td>\n",
  "</tr>\n",
  "\n",
  "\n",
  "<tr>\n",
  "<td class=\"right\">10</td>\n",
  "<td class=\"right\">2.00000</td>\n",
  "<td class=\"right\">4.00000</td>\n",
  "<td class=\"right\">3.00000</td>\n",
  "</tr>\n",
  "</tbody>\n",
  "</table>\n",
  "\n",
  "We can write the Gauss-Seidel method as:\n",
  "\n",
  "\\begin{equation}\n",
  "x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^n a_{ij} x_j^{(k)} \\right), \\qquad i=1, 2, \\cdots, n\n",
  "\\end{equation}\n",
  "\n",
  "Now we are using the new values of x as soon as they are available at each iteration.\n",
  "\n",
  "However, we could do even better and rather than just use the latest value of x we might effectively interpolate (or extrapolate) between the old value of x and the latest value of x by weighting between the two – this yields the Gauss-Seidel method with relaxation:\n",
  "\n",
  "\\begin{equation}\n",
  "x_i^{(k+1)} = \\frac{\\omega}{a_{ii}} \\left(b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^n a_{ij} x_j^{(k)} \\right) + (1-\\omega) x_i^{(k)}, \\qquad i=1, 2, \\cdots, n\n",
  "\\end{equation}\n",
  "\n",
  "where $\\omega$ is the relaxation parameter and:\n",
  "-   if $0 < \\omega < 1$ then we have *under-relaxation*\n",
  "-   if $\\omega > 1$ then we have *over-relaxation*.\n",
  "\n",
  "It is common to also call this method **Successive over relaxation (SOR)**.\n",
  "\n",
  "## Convergence\n",
  "\n",
  "The method always convergences if matrix $A$ is either:\n",
  "-   *strictly diagonally dominant*\n",
  "-   symmetric positive-definite, i.e. $A$ should be symmetric ($A^T = A$) and for any non-zero  column vector $x$,\n",
  "\n",
  "\\begin{equation}\n",
  "x^T A x > 0.\n",
  "\\end{equation}\n",
  "\n",
  "An equivalent way of finding out if a matrix is positive-definite is that all its eigenvalues should be strictly positive.\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "def ispositive(A):\n",
  "    \"\"\"Return True if the input matrix is positive-definite\"\"\"\n",
  "    return np.all(np.linalg.eigvals(A) > 0)\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "```ipython\n",
  "def issymmetric(A):\n",
  "    \"\"\"Return True if the input matrix is symmetric\"\"\"\n",
  "    np.all(A.T == A)\n",
  "```\n",
  "\n",
  "## Adaptive relaxation parameter\n",
  "\n",
  "Whilst it is not generally possible to compute the optimal value of $\\omega$ before starting, a formula exists that could be used during run time to estimate it during the calculation and it can be tuned whilst the calculation progresses.\n",
  "\n",
  "A near optimal estimate for $\\omega$ can be obtained based on the change in the solution between two iterations\n",
  "\n",
  "\\begin{equation}\n",
  "\\Delta x^{(k)} = \\sqrt{\\sum_{i=1}^n \\left(x_i^{(k)} - x_i^{(k-1)}\\right)^2},\n",
  "\\end{equation}\n",
  "\n",
  "\\begin{equation}\n",
  "\\omega_{opt} \\approx \\frac{2}{1 + \\sqrt{1 - \\left(\\frac{\\Delta x^{(k+p)}}{\\Delta x^{(k)}}\\right)^{1/p}}},\n",
  "\\end{equation}\n",
  "\n",
  "where $k$ and $p$ are positive integers. Typical values are $k=10$ and $p=1$.\n",
  "\n",
  "## Example 1\n",
  "\n",
  "Based on example 2.17 p 90 in Reference 3. Solve the following system of equations using Gauss-Seidel with or without relaxation.\n",
  "\n",
  "\n",
  "\n",
  "\n",
  "\\begin{equation}\n",
  "\\begin{pmatrix}\n",
  "          2 & -1 &  0 & \\cdots & 0 & 1 \\\\\n",
  "          -1 & \\ddots & \\ddots & 0 & \\cdots & 0 \\\\\n",
  "          0 & \\ddots & \\ddots & \\ddots & \\ddots   &  \\vdots       \\\\\n",
  "          \\vdots & \\ddots & \\ddots & \\ddots & \\ddots & 0 \\\\\n",
  "          0 & \\cdots & 0 & \\ddots & \\ddots & -1 \\\\\n",
  "          1 & 0 &  \\cdots & 0 & -1 & 2 \\\\\n",
  "\\end{pmatrix}\n",
  "\\begin{pmatrix}\n",
  "x_1 \\\\ x_2 \\\\ \\vdots \\\\ \\vdots \\\\ x_{n-1} \\\\ x_{n}\n",
  "\\end{pmatrix}\n",
  "=\n",
  "\\begin{pmatrix}\n",
  "0 \\\\ 0 \\\\ \\vdots \\\\ \\vdots \\\\ 0 \\\\ 0 \\\\ 1\n",
  "\\end{pmatrix}\n",
  "\\end{equation}\n",
  "\n",
  "The Gauss-Seidel iteration equation is reproduced here for convenience:\n",
  "\n",
  "\\begin{equation}\n",
  "x_i^{(k+1)} = \\frac{\\omega}{a_{ii}} \\left(b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^n a_{ij} x_j^{(k)} \\right) + (1-\\omega) x_i^{(k)}, \\qquad i=1, 2, \\cdots, n\n",
  "\\end{equation}\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "## example2_17\n",
  "def iterate(x, omega=1.0):\n",
  "    \"\"\"Use the Gauss-Seidel algorithm to iterate the estimated solution\n",
  "    vector x to equation A x = b, and return the improved solution.\n",
  "\n",
  "    x : array of floats of size n\n",
  "         Solution vector.\n",
  "    omega : float\n",
  "         Relaxation factor.\n",
  "\n",
  "    \"\"\"\n",
  "    n = len(x)\n",
  "    x[0] = omega*(x[1] - x[n - 1]) / 2.0 + (1.0 - omega) * x[0]\n",
  "    for i in range(1, n - 1):\n",
  "        x[i] = omega * (x[i - 1] + x[i + 1]) / 2.0 + (1.0 - omega) * x[i]\n",
  "    x[n - 1] = (omega * (1.0 - x[0] + x[n - 2]) / 2.0 +\n",
  "                (1.0 - omega) * x[n - 1])\n",
  "    return x\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "\n",
  "from numpy import dot, sqrt\n",
  "def gauss_seidel(iterate, x, tol=1.0e-9, relaxation=False):\n",
  "    \"\"\" x, niter, omega = gauss_seidel(iterate, x, tol=1.0e-9, omega=1.0)\n",
  "\n",
  "    Gauss-Seidel method for solving [A]{x} = {b}.\n",
  "\n",
  "    The matrix [A] should be sparse. User must supply the\n",
  "    function iterate(x, omega) that returns the improved {x},\n",
  "    given the current {x}. 'omega' is the relaxation factor.\n",
  "    \"\"\"\n",
  "    omega = 1.0\n",
  "    k = 10\n",
  "    p = 1\n",
  "    for i in range(1,501):\n",
  "        xold = x.copy()\n",
  "        x = iterate(x, omega)\n",
  "        dx = sqrt(dot(x - xold, x - xold))\n",
  "        if dx < tol:\n",
  "            return x, i, omega\n",
  "        if relaxation:\n",
  "            # Compute of relaxation factor after k+p iterations\n",
  "            if i == k:\n",
  "                dx1 = dx\n",
  "            if i == k + p:\n",
  "                dx2 = dx\n",
  "                omega = 2.0 / (1.0 + sqrt(1.0 - (dx2 / dx1)**(1.0 / p)))\n",
  "    print 'Gauss-Seidel failed to converge'\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "def iterate2(x, omega=1):\n",
  "    \"\"\"Use the Gauss-Seidel algorithm to iterate the estimated solution\n",
  "    vector {x} to equation\n",
  "         A x = b,\n",
  "    where matrix [A] and vector {b} are defined above, and return the\n",
  "    improved solution.\n",
  "    \"\"\"\n",
  "    # TODO\n",
  "\n",
  "# Use iterate2 and function 'gauss_seidel' to solve the system\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "-   Run the program with $n=20$ and compare the number of iterations with that in Example 1.\n",
  "\n",
  "## Exercise 3\n",
  "\n",
  "-   Solve Example one with the Jacobi approach by defining a suitable matrix $A$, and a suitable array $b$ for a given value of $n$. Skeleton code below.\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "def get_matrix_A(n):\n",
  "    \"\"\"Return the matrix [A] in Example 1 for a given value of n\"\"\"\n",
  "    pass  # TODO\n",
  "\n",
  "def get_vector_b(n):\n",
  "    \"\"\"Return the vector {b} in Example 1 for a given value of n\"\"\"\n",
  "    pass  # TODO\n",
  "\n",
  "def jacobi_solver(n=20):\n",
  "    A = get_matrix_A(n)\n",
  "    b = get_matrix_b(n)\n",
  "    return jacobi(A, b, n)\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "-   Time the solution and compare with Gauss-Seidel\n",
  "-   Solve and time the Gauss-Seidel method for the above problem using the `%%timeit` magic command in Jupyter. How does the computation time scale with $n$?\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "%%timeit\n",
  "n = 25\n",
  "x1, niter, omega = gauss_seidel(iterate, zeros(n), True)\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "%%timeit\n",
  "# Uncomment once jacobi_solver has been defined\n",
  "#x2 = jacobi_solver(n)\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "-   Check that both solutions are in agreement, i.e. that $x_1 \\approx x_2$\n",
  "\n",
  "# Conclusions\n",
  "\n",
  "-   Linear systems can be solved using iterative methods\n",
  "-   The Jacobi algorithm:\n",
  "    -   refines the solution by expressing each variable $x_i^{(k+1)}$ in terms of all the other variables $\\{x_j^{(k)}\\}_{j \\neq i}$;\n",
  "    -   works for *strictly diagonally dominant* matrices.\n",
  "-   The Gauss-Seidel algorithm:\n",
  "    -   refines the solution by expressing each variable $x_i^{(k+1)}$ in\n",
  "        terms of $\\{x_j^{(k)}\\}_{j > i}$ and $\\{x_j^{(k+1)}\\}_{j < i}$\n",
  "    -   works for *strictly diagonally dominant* matrices **or** *symmetric positive definite* matrices.\n",
  "-   You should be able to test whether a particular matrix is suitable for the Jacobi or Gauss-Seidel algorithm.\n",
  "\n",
  "# References\n",
  "\n",
  "1.  Mathews, J.H. and Fink, K.D. “Numerical methods using Matlab: 3rd edition” Prentice-Hall. ISBN 0132700425. There is a 4th edition of this available (ISBN- 13: 978-0130652485)\n",
  "2.  From <http://quantstart.com/articles/Jacobi-Method-in-Python-and-NumPy>\n",
  "3.  Jaan Kiusalaas, [Numerical Methods in Engineering with Python](http://www.amazon.com/Numerical-Methods-Engineering-Python-Kiusalaas/dp/0521191327), 2010.\n",
  "\n"
  ]
 }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}