{
"cells": [
 {
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "<h1 align=\"center\"><font color=\"0066FF\" size=110>Ordinary Differential Equations II: Runge-Kutta and Advanced Methods</font></h1>\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "# Setup notebook\n",
  "import numpy as np\n",
  "# Uncomment next two lines for bigger fonts\n",
  "import matplotlib\n",
  "try:\n",
  "    %matplotlib inline\n",
  "except:\n",
  "    # not in notebook\n",
  "    pass\n",
  "from IPython.html.widgets import interact\n",
  "LECTURE = False\n",
  "if LECTURE:\n",
  "    size = 20\n",
  "    matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
  "    matplotlib.rcParams['axes.labelsize'] = size\n",
  "    matplotlib.rcParams['axes.titlesize'] = size\n",
  "    matplotlib.rcParams['xtick.labelsize'] = size * 0.6\n",
  "    matplotlib.rcParams['ytick.labelsize'] = size * 0.6\n",
  "import matplotlib.pyplot as plt\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "# Learning Outcomes\n",
  "\n",
  "-   Describe the rationale behind Runge-Kutta methods.\n",
  "-   Implement a Runge-Kutta method such as 4th order Runge-Kutta (RK4) given the intermediate steps and weighting coefficients.\n",
  "-   Solve a first order explicit initial value problem using RK4.\n",
  "-   Discuss the trade-off between reducing the step size and using a Runge-Kutta method of higher order.\n",
  "\n",
  "# Introduction\n",
  "\n",
  "In the previous lecture we discussed Euler's method, which is based on approximating the solution as a polynomial of order 1 using Taylor's theorem. Indeed, given an explicit ODE $y' = F(t, y(t))$, we have\n",
  "\n",
  "\\begin{equation}\n",
  "y(t_i + h) \\approx y(t_i) + h y'(t_i) = y(t_i) + h F(t, y(t_i)).\n",
  "\\end{equation}\n",
  "\n",
  "The function $y(t_i + h)$ is a polynomial of order 1 so Euler method is of order 1. This works well provided that the exact solution $y(t)$ looks like a straight line between within $[t_i, t_i + h]$. It is always possible to find a small enough $h$ such that this is the case, as long as our function is differentiable. However, this $h$ may be too small for our needs:  small values of $h$ imply that it takes a large number of steps to progress the solution to our desired final time $b$.\n",
  "\n",
  "It would be benefitial to be able to choose a bigger step $h$. The solution may not look like a straight line, but rather like a higher order polynomial. For example, it may be better described as a polynomial of order 2. Using Taylor's theorem to order 2, we can write\n",
  "\n",
  "\\begin{equation}\n",
  "y(t_i + h) \\approx y(t_i) + h y'(t_i) + \\frac{h^2}{2} y''(t_i).\n",
  "\\end{equation}\n",
  "\n",
  "But this time, we need an extra peace of information: the second order derivative $y''(t_i)$. More generally, if the solution varies like a polynomial of rder $n$, we can use\n",
  "\n",
  "\\begin{equation}\n",
  "y(t_i + h) \\approx y(t_i) + h y'(t_i) + \\frac{h^2}{2} y''(t_i) + \\cdots + \\frac{h^n}{n!} y^{(n)}(t_i),\n",
  "\\end{equation}\n",
  "\n",
  "but we then need to know the first $n$ derivatives at $t_i$: $y'(t_i), y''(t_i), \\cdots, y^{(n)}(t_i)$. If these derivatives can be computed accurately, Taylor's approximation is accurate as can be seen below.\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "# Taylor series\n",
  "def f(x):\n",
  "    \"\"\"Return real number f(x) given real number x.\"\"\"\n",
  "    return np.exp(x)\n",
  "    #return np.sin(x)\n",
  "def df(x, n):\n",
  "    \"\"\"Return a real number giving the n^th derivative of f at point x\"\"\"\n",
  "    return np.exp(x)\n",
  "    # since d^n sin(x) = d^n Imag{ exp(i x) } = Imag{ i^n exp( i x) } = Imag { exp (i (x + n pi/2))}\n",
  "    #return np.sin(x + n * np.pi / 2)\n",
  "\n",
  "def taylor(x, nmax=1, f=f, df=df, x0=0.0):\n",
  "    \"\"\"Evaluate Taylor series for input array 'x', up to order 'nmax', around 'x0'.\n",
  "    \"\"\"\n",
  "    y = f(x0)\n",
  "    n_factorial = 1.0\n",
  "    for n in xrange(1, nmax + 1):\n",
  "        n_factorial *= n\n",
  "        y +=  (x - x0)**n * df(x0, n) / n_factorial\n",
  "    return y\n",
  "\n",
  "x = np.linspace(0, 10, 1000)\n",
  "yexact = f(x)\n",
  "def approx(n=25):\n",
  "    plt.plot(x, yexact, 'k', lw=1, label='exact')\n",
  "    plt.plot(x, taylor(x, n), '--r', lw=2, label='taylor (n = %d)' % n)\n",
  "    plt.legend(loc=0)\n",
  "    yrange = yexact.max() - yexact.min()\n",
  "    plt.ylim([yexact.min() - 0.2 * yrange, yexact.max() + 0.2 * yrange])\n",
  "if LECTURE:\n",
  "    i = interact(approx, interact(n=(1, 50)))\n",
  "else:\n",
  "    approx()\n",
  "plt.savefig('fig03-01.pdf')\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "\n",
  "## Note\n",
  "\n",
  "We can choose bigger and bigger values for $h$. This is in fact how computers calculate transcendental functions like $\\exp$, $\\sin$ or $\\cos$. For example, using $t_i = 0$ in the above equation,\n",
  "\n",
  "\\begin{align}\n",
  "y(t) &= \\exp(t), & &\\Rightarrow& y^{(n)}(t_i) &= \\exp(t_i), & &\\Rightarrow& \\exp(h) &\\approx \\sum_{j = 0}^n \\frac{h^j}{j!} \\\\\n",
  "y(t) &= \\sin(t), & &\\Rightarrow& y^{(n)}(t_i) &= \\sin \\left(t_i + n \\frac{\\pi}{2} \\right), & &\\Rightarrow& \\sin(h) &\\approx \\sum_{j = 0}^n \\sin \\left(j \\frac{\\pi}{2}\\right) \\frac{h^j}{j!} = \\sum_{\\substack{j=1 \\\\ j \\text{ odd}}}^n (-1)^{\\frac{j - 1}{2}} \\frac{h^j}{j!}\n",
  "\\end{align}\n",
  "\n",
  "## Limitations of Taylor's approximation\n",
  "\n",
  "For an initial value problem, what we have is a function $F$ such that that for all $t$,\n",
  "\n",
  "\\begin{equation}\n",
  "y'(t) = F(t, y(t)).\n",
  "\\end{equation}\n",
  "\n",
  "We therefore have a lot of information about the first derivative, but none about higher order derivatives. We could try estimating higher order derivatives numerically but this is error prone. We need an alternative approach.\n",
  "\n",
  "# Runge-Kutta methods\n",
  "\n",
  "## Rationale\n",
  "\n",
  "One popular solution to the limitations of Taylor's approximation is to use a Runge-Kutta method. A Runge-Kutta method of order $n$ produces an estimate $y'_e$ for the effective slope of the solution $y(t)$ over the interval $[t_i, t_i + h]$, so that the following expression approximates $y(t_i + h)$ to order $n$:\n",
  "\n",
  "\\begin{equation}\n",
  "y(t_i + h) \\approx y(t_i) + h y'_e\n",
  "\\end{equation}\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "AVERAGE = False\n",
  "t = np.linspace(0, 5)\n",
  "h = 5\n",
  "y0 = 1000\n",
  "r = 0.1\n",
  "yexact = y0 * np.exp(r * t)\n",
  "\n",
  "def F(y):\n",
  "    return 0.1 * y\n",
  "F0 = F(yexact[0])\n",
  "F1 = F(yexact[-1])\n",
  "y_feuler = y0 + t * F0\n",
  "y_beuler = y0 + t * F1\n",
  "\n",
  "plt.figure(2)\n",
  "plt.clf()\n",
  "plt.plot(t, yexact, 'k-o', label='exact')\n",
  "plt.plot(t, y_feuler, '--', label='Euler')\n",
  "plt.plot(t, y_beuler, '--', label='backward Euler')\n",
  "if AVERAGE:\n",
  "    effective_slope = (F0 + F1) / 2\n",
  "    y_av = y0 + t * effective_slope\n",
  "    plt.plot(t, y_av, '--', label='effective slope?')\n",
  "plt.legend(loc=0)\n",
  "plt.xlabel('t')\n",
  "plt.ylabel('y')\n",
  "plt.savefig('fig03-02.pdf')\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "In Runge-Kutta methods, the effective slope $y'_e$ is obtained:\n",
  "1.  by estimating the slope $y'(t) = F(t, y)$ at different intermediate times within $[t_i, t_i + h]$.\n",
  "2.  by applying a weighted average to these slopes.\n",
  "\n",
  "Thus a $q$ stage Runge-Kutta method defines\n",
  "-   a set of $q$ intermediate times (&tau;<sub>j</sub>) such that $t_i \\leq \\tau_1 \\leq \\tau_2 \\leq \\cdots \\leq \\tau_q \\leq t_i + h$.\n",
  "-   a set of $q$ estimates for the slopes $k_1=y'(\\tau_1), k_2=y'(\\tau_2), \\cdots, k_q=y'(\\tau_q)$\n",
  "-   a set of weights $c_1$, $c_2, \\cdots c_q$ that define the weighted average giving the effective slope $y'_e$:\n",
  "\n",
  "\\begin{equation}\n",
  "y'_e = c_1 k_1 + c_2 k_2 + \\cdots + c_q k_q.\n",
  "\\end{equation}\n",
  "\n",
  "Combining the two equations above yields\n",
  "\n",
  "\\begin{equation}\n",
  "y_{i+1} = y_i + h(c_1 k_1 + c_2 k_2 + \\cdots + c_q k_q).\n",
  "\\end{equation}\n",
  "\n",
  "The rationale behind Runge-Kutta methods is to define the weighting coefficients $c_1, c_2, \\cdot, c_q$ so that the above expression matches Taylor's approximation for $y_{i+1} = y(t_i + h)$ to the desired order of accuracy. This is always possible to use a sufficient number of intermediate steps. We need $q \\geq n$ stages to obtain a Runge-Kutta method accurate of order $n$.\n",
  "\n",
  "## Example I: mid-point rule (RK2)\n",
  "\n",
  "For example, the mid-point rule is a stage 2 Runge-Kutta method such that:\n",
  "\n",
  "\\begin{align}\n",
  "\\tau_1 &= t_i, & \\tau_2 &= t_i + h = t_{i+1} \\\\\n",
  "c_1 &= \\frac{1}{2}  & c_2 &= \\frac{1}{2},\n",
  "\\end{align}\n",
  "\n",
  "\n",
  "so\n",
  "\n",
  "\\begin{align}\n",
  "y_{i+1} &= y_i + \\frac{h}{2}(k_1 + k_2), \\\\\n",
  "k_1 &= F(t_i, y_i),  \\\\\n",
  "k_2 &= F(t_i + h, y_i + h k_1).\n",
  "\\end{align}\n",
  "\n",
  "The weights $c_1$ and $c_2$ are such that the mid-point rule is accurate to order 2. This can proven by expanding $y_{i+1} = y(t_i + h)$ and $k_2$ using Taylor's approximation to order 2; matching the coefficients of order 1 and 2 yields two equations with two unknowns $c_1$ and $c_2$ whose solution is $c_1 = c_2 = 1/2$. The derivation is given in Appendix A.\n",
  "\n",
  "### Implementation\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "def rk2(F, a, b, ya, n):\n",
  "    \"\"\"Solve the first order initial value problem\n",
  "         y'(t) = F(t, y(t)), y(a) = ya,\n",
  "    using the mid-point Runge-Kutta method and return (tarr, yarr),\n",
  "    where tarr is the time grid (n uniformly spaced samples between a\n",
  "    and b) and yarr the solution\n",
  "\n",
  "    Parameters\n",
  "    ----------\n",
  "    F : function\n",
  "         A function of two variables of the form F(t, y), such that\n",
  "         y'(t) = F(t, y(t)).\n",
  "    a : float\n",
  "         Initial time.\n",
  "    b : float\n",
  "         Final time.\n",
  "    n : integer\n",
  "         Controls the step size of the time grid, h = (b - a) / (n - 1)\n",
  "    ya : float\n",
  "         Initial condition at ya = y(a).\n",
  "    \"\"\"\n",
  "    tarr = np.linspace(a, b, n)\n",
  "    h = tarr[1] - tarr[0]\n",
  "    ylst = []\n",
  "    yi = ya\n",
  "    for t in tarr:\n",
  "        ylst.append(yi)\n",
  "        k1 = F(t, yi)\n",
  "        k2 = F(t + h / 2.0, yi + h * k1)\n",
  "        yi += 0.5 * h * (k1 + k2)\n",
  "    yarr = np.array(ylst)\n",
  "    return tarr, yarr\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "### Results\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "def interest(ode_solver, n, r=0.1, y0=1000, t0=0.0, t1=5.0):\n",
  "    \"\"\"Solve ODE   y'(t) = r y(t), y(0) = y0 and return the absolute error.\n",
  "\n",
  "    ode_solver : function\n",
  "         A function ode_solver(F, a, b, ya, n) that solves an explicit\n",
  "         initial value problem y'(t) = F(t, y(t)) with initla\n",
  "         condition y(a) = ya. See 'euler', or 'rk2'.\n",
  "    n : integer, optional\n",
  "         The number of time steps\n",
  "    r : float, optional\n",
  "         The interest rate\n",
  "    y0 : float, optional\n",
  "         The amount of savings at the initial time t0.\n",
  "    t0 : float, optional\n",
  "         Initial time.\n",
  "    t1 : float, optional\n",
  "         Final time.\n",
  "    \"\"\"\n",
  "    # Exact solution\n",
  "    t = np.linspace(t0, t1)\n",
  "    y = y0 * np.exp(r * t)\n",
  "    y1 = y[-1]\n",
  "    print \"Savings after %d years = %f\" %(t1, y1)\n",
  "    # Plot the exact solution if the figure is empty\n",
  "    if not plt.gcf().axes:\n",
  "        plt.plot(t, y, 'o-k', label='exact', lw=4)\n",
  "        plt.xlabel('Time [years]')\n",
  "        plt.ylabel(u'Savings [£]')\n",
  "    # Numerical solution\n",
  "    F = lambda t, y: r * y  # the function y'(t) = F(t,y)\n",
  "    tarr, yarr = ode_solver(F, t0, t1, y0, n)\n",
  "    yarr1 = yarr[-1]\n",
  "    abs_err = abs(yarr1 - y1)\n",
  "    rel_err = abs_err / y1\n",
  "    print \"%s steps: estimated savings = %8.6f,\"\\\n",
  "          \" error = %8.6f (%5.6f %%)\" % (str(n).rjust(10), yarr1,\n",
  "                                         abs_err, 100 * rel_err)\n",
  "    plt.plot(tarr, yarr, label='n = %d' % n, lw=2)\n",
  "    plt.legend(loc=0)\n",
  "    return tarr, yarr, abs_err\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "Compute and plot the solution:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "nbsteps = [2, 4, 8, 16, 32, 64, 128]\n",
  "errlst = []\n",
  "plt.figure(3)\n",
  "plt.clf()\n",
  "for n in nbsteps:\n",
  "    tarr, yarr, abs_err = interest(rk2, n)\n",
  "    errlst.append(abs_err)\n",
  "plt.savefig('fig03-03.pdf')\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "Plot the absolute error:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "plt.figure(4)\n",
  "plt.clf()\n",
  "plt.loglog(nbsteps, errlst)\n",
  "plt.xlabel('Number of steps')\n",
  "plt.ylabel(u'Absolute error (t = %d years) [£]' % tarr[-1])\n",
  "plt.grid(which='both')\n",
  "plt.savefig('fig03-04.pdf')\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "\n",
  "## Example II: The Runge-Kutta method (RK4)\n",
  "\n",
  "The classical Runge-Kutta method, or simply *the* Runge-Kutta method, is given by\n",
  "\n",
  "\\begin{align}\n",
  "\\tau_1 &= t_i, & \\tau_2 &= t_i + \\frac{h}{2},&  \\tau_3 &= t_i + \\frac{h}{2}, & \\tau_4 &= t_i + h = t_{i+1} \\\\\n",
  "c_1 &= 1/6, & c_2 &= 1/3,&  c_3 &= 1/3, & c_4 &= 1/6 \\\\\n",
  "\\end{align}\n",
  "\n",
  "\\begin{align}\n",
  "y_{i+1} &= y_i + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4).\n",
  "\\end{align}\n",
  "\n",
  "where\n",
  "\n",
  "\\begin{align}\n",
  "k_1 &= F(t_i, y_i),  &\n",
  "k_2 &= F(t_i + \\frac{h}{2}, y_i + \\frac{h}{2} k_1), \\\\\n",
  "k_3 &= F(t_i + \\frac{h}{2}, y_i + \\frac{h}{2} k_2), &\n",
  "k_4 &= F(t_i + h, y_i + h k_3).\n",
  "\\end{align}\n",
  "\n",
  "The weights are such that RK4 is accurate to order 4. The weights can be obtained by following the same derivation as that presented in Appendix A for RK2. Thus, expanding $y_{i+1} = y(t_i + h)$, $k_2$, $k_3$ and $k_4$ using Taylor's approximation to order 4, and matching the coefficients of orders 1 to 4 yields four equations with four unknowns $c_1, c_2, c_3$ and $c_4$ whose solution is $c_1=c_4=1/6$ and $c_2=c_3=1/3$. The derivation is left as an exercise to the reader. The derivation is given in [​1] or [2, 3].\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "def rk4(F, a, b, ya, n):\n",
  "    \"\"\"Solve the first order initial value problem\n",
  "         y'(t) = F(t, y(t)),\n",
  "          y(a) = ya,\n",
  "    using the Runge-Kutta method and return a tuple made of two arrays\n",
  "    (tarr, yarr) where 'ya' approximates the solution on a uniformly\n",
  "    spaced grid 'tarr' over [a, b] with n elements.\n",
  "\n",
  "    Parameters\n",
  "    ----------\n",
  "    F : function\n",
  "         A function of two variables of the form F(t, y), such that\n",
  "         y'(t) = F(t, y(t)).\n",
  "    a : float\n",
  "         Initial time.\n",
  "    b : float\n",
  "         Final time.\n",
  "    n : integer\n",
  "         Controls the step size of the time grid, h = (b - a) / (n - 1)\n",
  "    ya : float\n",
  "         Initial condition at ya = y(a).\n",
  "    \"\"\"\n",
  "    tarr = np.linspace(a, b, n)\n",
  "    h = tarr[1] - tarr[0]\n",
  "    ylst = []\n",
  "    yi = ya\n",
  "    for t in tarr:\n",
  "        ylst.append(yi)\n",
  "        k1 = F(t, yi)\n",
  "        k2 = F(t + 0.5 * h, yi + 0.5 * h * k1)\n",
  "        k3 = F(t + 0.5 * h, yi + 0.5 * h * k2)\n",
  "        k4 = F(t + h, yi + h * k3)\n",
  "        yi +=  h / 6.0 * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n",
  "    yarr = np.array(ylst)\n",
  "    return tarr, yarr\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "Compute and plot the solution using RK4:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "#nbsteps = [10, 100, 1000, 10000]\n",
  "errlst = []\n",
  "plt.figure(5)\n",
  "plt.clf()\n",
  "for n in nbsteps:\n",
  "    tarr, yarr, abs_err = interest(rk4, n)\n",
  "    errlst.append(abs_err)\n",
  "plt.savefig('fig03-05.pdf')\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "Plot the absolute error using RK4:\n",
  "\n"
  ]
 },
{
 "cell_type": "code",
 "metadata": {},
  "outputs": [],
 "execution_count": 1,

 "source": [
  "plt.figure(6)\n",
  "plt.clf()\n",
  "plt.loglog(nbsteps, errlst)\n",
  "plt.xlabel('Number of steps')\n",
  "plt.ylabel(u'Absolute error (t = %d years) [£]' % tarr[-1])\n",
  "plt.grid(which='both')\n",
  "plt.savefig('fig03-06.pdf')\n",
  "\n"
  ]
 },
{
 "cell_type": "markdown",
 "metadata": {},
  
 "source": [
  "\n",
  "## Efficiency of Runge-Kutta methods\n",
  "\n",
  "Accurate results can be obtained by:\n",
  "1.  decreasing the time step $h$;\n",
  "2.  using a higher order method.\n",
  "\n",
  "Higher order methods are more accurate but also more expansive, because they do more work during each time step. The amount of work being done may become prohibitive, so that it may be more efficient to use a lower order method with a smaller time step.  There is therefore a trade-off between accuracy and computational cost. For Runge-Kutta methods, the peak efficiency is\n",
  "\n",
  "# Stability and stiffness\n",
  "\n",
  "Instead of approaching the exact solution $y(t)$ to a particular ODE, the numerical solution may diverge from it. This is due to stability issues. Stability depends on 3 factors:\n",
  "-   the differential equation.\n",
  "-   the method of solution.\n",
  "-   the step size.\n",
  "\n",
  "Some differential equations are particularly challenging to solve numerically. These are usually vector ODEs in which some components vary much more rapidly than other components [​4]. The step size is then constrained by the component that varies most rapidly. See Exercise 2 in the Self Study section for an example of stiffness and stability issues.\n",
  "\n",
  "Before applying a particular method such as RK4 to solve an ODE, you should investigate the stiffness of the ODE and the stability of your problem, otherwise you may get an incorrect solution.\n",
  "\n",
  "# Beyond Runge-Kutta\n",
  "\n",
  "-   *Adaptive methods* allow us to take big steps when the function is smooth, but tiptoe more carefully when the function is varying more. A typical scheme might try a step size of $h$ and then $2h$ and adapt accordingly.\n",
  "-   More sophisticated methods e.g. *Runge-Kutta-Fehlberg* (RKF45) is a further refinement of the method which also use a 4<sup>th</sup> order and 5<sup>th</sup> order approximation which enable the truncation error to be estimated and the step size to be adapted accordingly.\n",
  "-   The *Bulirsch-Stoer* Algorithm takes this one step further (no pun intended) and carefully extrapolates to what would happen if the step size was zero and judicious choice of approximation of the function to produce what is generally considered to be a very good way to solve a wide class of ordinary differential equation problems.\n",
  "-   Buyer beware that methods can get stuck if the function has discontinuities in the range&#x2026;\n",
  "\n",
  "# Conclusions\n",
  "\n",
  "-   Given and ODE $y'(t) = F(t, y(t))$ with $y(t_i) = y_i$, Runge-Kutta methods estimate the derivative at intermediate times using $y_i$ and $F(t, y(t)$ between $t_i$ and $t_i + h$, and use a weighted average of these estimates to approximate $y_{i+1}$.\n",
  "-   You should be able to write an implementation of RK4 based on\n",
  "\n",
  "\\begin{align}\n",
  "\\tau_1 &= t_i, & \\tau_2 &= t_i + \\frac{h}{2},&  \\tau_3 &= t_i + \\frac{h}{2}, & \\tau_4 &= t_i + h = t_{i+1} \\\\\n",
  "c_1 &= 1/6, & c_2 &= 1/3,&  c_3 &= 1/3, & c_4 &= 1/6 \\\\\n",
  "\\end{align}\n",
  "\n",
  "\\begin{align}\n",
  "y_{i+1} &= y_i + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4).\n",
  "\\end{align}\n",
  "\n",
  "where\n",
  "\n",
  "\\begin{align}\n",
  "k_1 &= F(t_i, y_i),  &\n",
  "k_2 &= F(t_i + \\frac{h}{2}, y_i + \\frac{h}{2} k_1), \\\\\n",
  "k_3 &= F(t_i + \\frac{h}{2}, y_i + \\frac{h}{2} k_2), &\n",
  "k_4 &= F(t_i + h, y_i + h k_3).\n",
  "\\end{align}\n",
  "\n",
  "-   You should be able to solve an initial value problem using RK4 or similar methods.\n",
  "-   There is a trade-off between the order of the method and the computational cost. Higher order methods are more accurate but more costly, so it may be more efficient to use a lower order method with a smaller step size.\n",
  "\n",
  "# Self study\n",
  "\n",
  "-   Describe in your own words the rationale behind Runge-Kutta methods.\n",
  "-   Use Euler and RK4 to solve the following ODE between 0 and 1\n",
  "\n",
  "\\begin{align}\n",
  "y'(t) &= -15 y(t) \\\\\n",
  "y(0) &= 1\n",
  "\\end{align}\n",
  "\n",
  "What happens when you use a time step $h$ larger than 0.25?\n",
  "-   Use RK4 to solve the following inital value problem between 0 and $2\\pi$\n",
  "\n",
  "\\begin{align}\n",
  "y'(t) &= \\cos(y(t)) \\\\\n",
  "y(0) &= 0\n",
  "\\end{align}\n",
  "\n",
  "Compare your result with the exact solution $y(t) = \\sin(t)$\n",
  "-   Implement RK6, defined in Appendix B, and solve the ODE in example 1 using it. Compare the time needed to reach a desired level of accuracy using RK6 compared to RK4. Which is more efficient?\n",
  "\n",
  "# References\n",
  "\n",
  "1.  Lyu, Ling-Hsiao (2013), *Numerical Simulation of Space Plasmas (I)* [AP-4036], Appendix C.2.3 [{pdf}](http://www.ss.ncu.edu.tw/~lyu/lecture_files_en/lyu_NSSP_Notes/Lyu_NSSP_AppendixC.pdf())\n",
  "2.  Mathews, J.H. and Fink, K.D. “Numerical methods using Matlab: 3rd edition” Prentice-Hall. ISBN 0132700425. There is a 4th edition of this available (ISBN-13: 978-0130652485)\n",
  "3.  Stoer J and Bulirsch R (2010) “Introduction to Numerical Analysis” Springer. ISBN 144193006X\n",
  "\n",
  "# Appendix A: derivation of the mid-point rule (RK2)\n",
  "\n",
  "In the mid-point rule, the two intermediate times are $\\tau_1 = t_i$ and $\\tau_2 = t_i + h/2$. We seek the weighting coefficients $c_1$ and $c_2$ such that the following Runge-Kutta approximation is accurate to order 2\n",
  "\n",
  "\\begin{align}\n",
  "y(t_i + h) &= y_i + h(c_1 k_1 + c_2 k_2), &\n",
  "k_1 &= F(t_i, y_i),  & k_2 &= F(t_i + h, y_i + h k_1).\n",
  "\\end{align}\n",
  "\n",
  "Expanding the slope estimate $k_2$ using Taylor's theorem, we have\n",
  "For example\n",
  "\n",
  "\\begin{align}\n",
  "k_2 &= F(t_i + h, y_i + h k_1) \\equiv K_2(h) \\\\\n",
  "    &\\approx K_2(0) + h K_2'(0) \\\\\n",
  "    &\\approx F(t_i, y_i) + h F'(t_i, y_i) \\equiv F_i + h F_i',\n",
  "\\end{align}\n",
  "\n",
  "where we have introduced the function $K_2(h) = F(t_i + h, y_i + k_1 h)$ and where $F'$ denotes the derivative of $t \\mapsto F(t, y(t))$. Substituting the results into our Runge-Kutta equation, and using $k_1 = F_i$,  yields\n",
  "\n",
  "\\begin{align}\n",
  "y(t_i + h) &\\approx y_i + h (c_1 + c_2) F_i + h^2 c_2 F_i'.\n",
  "\\end{align}\n",
  "\n",
  "If we also expand the left hand side $y(t_i + h)$ using Taylor's expansion to order 2, we get\n",
  "\n",
  "\\begin{equation}\n",
  "y_i + h F_i + \\frac{h^2}{2} F_i' \\approx y_i + h (c_1 + c_2) F_i + h^2 c_2 F_i'.\n",
  "\\end{equation}\n",
  "\n",
  "Equating the coefficients of $h$ and $h^2$ yields\n",
  "\n",
  "\\begin{equation}\n",
  "\\left\\{\n",
  "\\begin{aligned}\n",
  "c_1 + c_2 &= 1 \\\\\n",
  "c_2 = \\frac{1}{2}\n",
  "\\end{aligned}\n",
  "\\right.\n",
  "\\end{equation}\n",
  "\n",
  "so $c_1 = c_2 = 1/2$, which gives the mid-point rule\n",
  "\n",
  "\\begin{align}\n",
  "y_{i+1} &= y_i + \\frac{h}{2} (F(t_i, y_i) +  F(t_i + \\frac{h}{2}, y_i + \\frac{h}{2}k_1).\n",
  "\\end{align}\n",
  "\n",
  "# Appendix B: Higher order Runge-Kutta methods\n",
  "\n",
  "Reference [​1] presents similar derivations for Runge-Kutta methods of order 3,4, 5 and 6, assuming intermediate points such that\n",
  "\n",
  "\\begin{align}\n",
  "\\tau_1 &= t_i, &\n",
  "\\tau_q &= t_{i+1}, &\n",
  "\\tau_j &= \\frac{t_i + t_{i+1}}{2} \\quad \\text{for all} \\quad $1 < j < q$\n",
  "\\end{align}\n",
  "\n",
  "The weights are given below:\n",
  "-   Order 3\n",
  "\n",
  "\\begin{align}\n",
  "c_1 &= \\frac{2}{3!} = \\frac{1}{3}, & c_2 &= \\frac{1}{3},& c_3 &= \\frac{2}{3!} = \\frac{1}{3}\n",
  "\\end{align}\n",
  "\n",
  "-   Order 4\n",
  "\n",
  "\\begin{align}\n",
  "c_1 &= \\frac{2^2}{4!} = \\frac{1}{6}, & c_2 &= \\frac{1}{3},&  c_3 &= \\frac{1}{3}, & c_4 &= \\frac{2^2}{4!} = \\frac{1}{6}\n",
  "\\end{align}\n",
  "\n",
  "-   Order 5\n",
  "\n",
  "\\begin{align}\n",
  "c_1 &= \\frac{2^3}{5!} = \\frac{1}{15}, & c_2 &= \\frac{1}{3},&  c_3 &= \\frac{1}{3}, & c_4 &= \\frac{1}{5}, & c_5 &= \\frac{2^2}{4!} = \\frac{1}{15}\n",
  "\\end{align}\n",
  "\n",
  "-   Order 6\n",
  "\n",
  "\\begin{align}\n",
  "c_1 &= \\frac{2^4}{6!} = \\frac{1}{45}, & c_2 &= \\frac{1}{3},&  c_3 &= \\frac{1}{3}, & c_4 &= \\frac{1}{5}, & c_5 &= \\frac{4}{15}, & c_6 = \\frac{2^4}{6!} = \\frac{1}{45}\n",
  "\\end{align}\n",
  "\n",
  "Note that the coefficients\n",
  "-   tend to be symmetrical\n",
  "-   $c_1 = c_q = 2^{q-2} / q!$\n",
  "-   $c_1 + c_2 + \\cdots + c_q = 1$.\n",
  "-   Most of the interior coefficients $c_j,1 < j < q$ for the order $q$ Runge-Kutta scheme are identical to those from the stage $q-1$ Runge-Kutta scheme.\n",
  "\n"
  ]
 }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}